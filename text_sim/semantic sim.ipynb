{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "import json\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "with open('movie_wordlist.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = data['movie_title']\n",
    "movie_content = data['movie_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = []\n",
    "f = open('user_data.txt', encoding='utf-8')\n",
    "for i in f:\n",
    "    i=i.strip().split('\\n')\n",
    "    user_text.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:20:36,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-08-08 21:20:36,517 : INFO : built Dictionary(481 unique tokens: ['academy', 'action', 'african', 'all-time', 'america']...) from 3 documents (total 2226 corpus positions)\n",
      "2018-08-08 21:20:36,518 : INFO : saving Dictionary object under movie_words.dict, separately None\n",
      "2018-08-08 21:20:36,520 : INFO : saved movie_words.dict\n"
     ]
    }
   ],
   "source": [
    "#similarity between user_text and movie content\n",
    "texts = movie_content\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('movie_words.dict')\n",
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = user_text\n",
    "new_vec = dictionary.doc2bow(user_text)\n",
    "#print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:21:23,056 : INFO : storing corpus in Matrix Market format to m_text.mm\n",
      "2018-08-08 21:21:23,058 : INFO : saving sparse matrix to m_text.mm\n",
      "2018-08-08 21:21:23,059 : INFO : PROGRESS: saving document #0\n",
      "2018-08-08 21:21:23,060 : INFO : saved 3x481 matrix, density=37.976% (548/1443)\n",
      "2018-08-08 21:21:23,062 : INFO : saving MmCorpus index to m_text.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('m_text.mm', corpus)\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:42:54,468 : INFO : loaded corpus index from m_text.mm.index\n",
      "2018-08-08 21:42:54,470 : INFO : initializing cython corpus reader from m_text.mm\n",
      "2018-08-08 21:42:54,471 : INFO : accepted corpus with 3 documents, 481 features, 548 non-zero entries\n",
      "2018-08-08 21:42:54,472 : INFO : collecting document frequencies\n",
      "2018-08-08 21:42:54,473 : INFO : PROGRESS: processing document #0\n",
      "2018-08-08 21:42:54,474 : INFO : calculating IDF weights for 3 documents and 480 features (548 matrix non-zeros)\n",
      "2018-08-08 21:42:54,477 : INFO : using serial LSI version on this node\n",
      "2018-08-08 21:42:54,477 : INFO : updating model with new documents\n",
      "2018-08-08 21:42:54,480 : INFO : preparing a new chunk of documents\n",
      "2018-08-08 21:42:54,481 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-08-08 21:42:54,482 : INFO : 1st phase: constructing (481, 105) action matrix\n",
      "2018-08-08 21:42:54,483 : INFO : orthonormalizing (481, 105) action matrix\n",
      "2018-08-08 21:42:54,495 : INFO : 2nd phase: running dense svd on (105, 3) matrix\n",
      "2018-08-08 21:42:54,497 : INFO : computing the final decomposition\n",
      "2018-08-08 21:42:54,498 : INFO : keeping 3 factors (discarding 0.000% of energy spectrum)\n",
      "2018-08-08 21:42:54,500 : INFO : processed documents up to #3\n",
      "2018-08-08 21:42:54,502 : INFO : topic #0(1.018): 0.390*\"martian\" + 0.363*\"chinese\" + 0.253*\"feng\" + 0.176*\"wolf\" + 0.133*\"space\" + 0.133*\"character\" + 0.124*\"gravity\" + 0.121*\"factory\" + 0.116*\"director\" + 0.113*\"weekend\"\n",
      "2018-08-08 21:42:54,502 : INFO : topic #1(0.999): 0.323*\"goal\" + 0.323*\"father\" + 0.277*\"manager\" + 0.231*\"dream\" + 0.231*\"match\" + 0.231*\"song\" + 0.185*\"soundtrack\" + 0.185*\"becker\" + 0.185*\"oasis\" + -0.160*\"chinese\"\n",
      "2018-08-08 21:42:54,503 : INFO : topic #2(0.983): 0.417*\"martian\" + -0.387*\"chinese\" + -0.270*\"feng\" + -0.188*\"wolf\" + 0.142*\"character\" + 0.142*\"space\" + 0.133*\"gravity\" + -0.129*\"factory\" + 0.124*\"director\" + 0.115*\"novel\"\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "corpus = corpora.MmCorpus('m_text.mm')\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "doc_bow = new_vec\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=5)\n",
    "corpus_lsi = lsi[corpus_tfidf] #bow->tfidf->fold-in-lsi\n",
    "vec_bow = new_vec\n",
    "vec_lsi = lsi[vec_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-09 01:29:21,793 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2018-08-09 01:29:21,795 : INFO : creating matrix with 3 documents and 3 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.8632605), (1, 0.44300938), (2, 0.35772368)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "sims = index[vec_lsi]\n",
    "#print(list(enumerate(sims)))\n",
    "similarity = {}\n",
    "sim_id = []\n",
    "sim_rate = []\n",
    "for i, element in enumerate(sims):\n",
    "    sim_id.append(i+1)\n",
    "    sim_rate.append(element)\n",
    "similarity = dict(zip(sim_id, sim_rate))\n",
    "similarity = sorted(similarity.items(), key=lambda item:item[1], reverse=True)\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
