{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2018-08-08 21:56:10,606 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "                          \"A survey of user opinion of computer system response time\",\n",
    "                          \"The EPS user interface management system\",\n",
    "                          \"System and human system engineering testing of EPS\",\n",
    "                          \"Relation of user perceived response time to error measurement\",\n",
    "                          \"The generation of random binary unordered trees\",\n",
    "                          \"The intersection graph of paths in trees\",\n",
    "                          \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "                          \"Graph minors A survey\"]\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "\n",
    "#去掉频次为1的词\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] +=1\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "from pprint import pprint\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:56:11,381 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-08-08 21:56:11,382 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2018-08-08 21:56:11,383 : INFO : saving Dictionary object under deerwester.dict, separately None\n",
      "2018-08-08 21:56:11,384 : INFO : saved deerwester.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('deerwester.dict')\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "#doc2bow()统计每个不同单词的出现次数，把词转化成整数词id并且返回稀疏向量结果\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:56:13,990 : INFO : storing corpus in Matrix Market format to deerwester.mm\n",
      "2018-08-08 21:56:13,992 : INFO : saving sparse matrix to deerwester.mm\n",
      "2018-08-08 21:56:13,993 : INFO : PROGRESS: saving document #0\n",
      "2018-08-08 21:56:13,994 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
      "2018-08-08 21:56:13,995 : INFO : saving MmCorpus index to deerwester.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('deerwester.mm', corpus)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
      "[(1, 1), (5, 2), (8, 1)]\n",
      "[(3, 1), (6, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(4, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in open('mycorpus.txt'):\n",
    "            yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "corpus_memory_friendly = MyCorpus()\n",
    "for vector in corpus_memory_friendly:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:56:15,813 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-08-08 21:56:15,815 : INFO : built Dictionary(42 unique tokens: ['abc', 'applications', 'computer', 'for', 'human']...) from 9 documents (total 69 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "from six import iteritems\n",
    "dictionary = corpora.Dictionary(line.lower().split() for line in open('mycorpus.txt'))\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids)\n",
    "dictionary.compactify() \n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:56:16,726 : INFO : loading Dictionary object from deerwester.dict\n",
      "2018-08-08 21:56:16,727 : INFO : loaded deerwester.dict\n",
      "2018-08-08 21:56:16,729 : INFO : loaded corpus index from deerwester.mm.index\n",
      "2018-08-08 21:56:16,729 : INFO : initializing cython corpus reader from deerwester.mm\n",
      "2018-08-08 21:56:16,730 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used files generated from first tutorial\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import os\n",
    "if (os.path.exists(\"deerwester.dict\")):\n",
    "    dictionary = corpora.Dictionary.load('deerwester.dict')\n",
    "    corpus = corpora.MmCorpus('deerwester.mm')\n",
    "    print(\"Used files generated from first tutorial\")\n",
    "else:\n",
    "    print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:56:17,531 : INFO : collecting document frequencies\n",
      "2018-08-08 21:56:17,532 : INFO : PROGRESS: processing document #0\n",
      "2018-08-08 21:56:17,533 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
      "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "#tfidf model\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "doc_bow = [(0,1),(1,1)]\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:56:18,313 : INFO : using serial LSI version on this node\n",
      "2018-08-08 21:56:18,314 : INFO : updating model with new documents\n",
      "2018-08-08 21:56:18,315 : INFO : preparing a new chunk of documents\n",
      "2018-08-08 21:56:18,316 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-08-08 21:56:18,317 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2018-08-08 21:56:18,318 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2018-08-08 21:56:18,326 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2018-08-08 21:56:18,327 : INFO : computing the final decomposition\n",
      "2018-08-08 21:56:18,328 : INFO : keeping 2 factors (discarding 47.565% of energy spectrum)\n",
      "2018-08-08 21:56:18,329 : INFO : processed documents up to #9\n",
      "2018-08-08 21:56:18,330 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "2018-08-08 21:56:18,331 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n",
      "2018-08-08 21:56:18,335 : INFO : saving Projection object under model.lsi.projection, separately None\n",
      "2018-08-08 21:56:18,337 : INFO : saved model.lsi.projection\n",
      "2018-08-08 21:56:18,338 : INFO : saving LsiModel object under model.lsi, separately None\n",
      "2018-08-08 21:56:18,338 : INFO : not storing attribute projection\n",
      "2018-08-08 21:56:18,339 : INFO : not storing attribute dispatcher\n",
      "2018-08-08 21:56:18,341 : INFO : saved model.lsi\n",
      "2018-08-08 21:56:18,342 : INFO : loading LsiModel object from model.lsi\n",
      "2018-08-08 21:56:18,343 : INFO : loading id2word recursively from model.lsi.id2word.* with mmap=None\n",
      "2018-08-08 21:56:18,343 : INFO : setting ignored attribute projection to None\n",
      "2018-08-08 21:56:18,344 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-08-08 21:56:18,345 : INFO : loaded model.lsi\n",
      "2018-08-08 21:56:18,346 : INFO : loading LsiModel object from model.lsi.projection\n",
      "2018-08-08 21:56:18,347 : INFO : loaded model.lsi.projection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.06600783396090411), (1, -0.5200703306361846)]\n",
      "[(0, 0.19667592859142516), (1, -0.760956316770005)]\n",
      "[(0, 0.08992639972446498), (1, -0.7241860626752505)]\n",
      "[(0, 0.07585847652178251), (1, -0.6320551586003423)]\n",
      "[(0, 0.10150299184980113), (1, -0.573730848300296)]\n",
      "[(0, 0.7032108939378315), (1, 0.16115180214025887)]\n",
      "[(0, 0.8774787673119835), (1, 0.167589068646595)]\n",
      "[(0, 0.9098624686818579), (1, 0.14086553628719092)]\n",
      "[(0, 0.6165825350569281), (1, -0.05392907566389356)]\n"
     ]
    }
   ],
   "source": [
    "#lsi model\n",
    "#初始化LSI转换\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi[corpus_tfidf] #bow->tfidf->fold-in-lsi\n",
    "#lsi.print_topics(2)\n",
    "for doc in corpus_lsi:\n",
    "    print(doc)\n",
    "lsi.save('model.lsi')\n",
    "lsi = models.LsiModel.load('model.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:56:19,258 : INFO : loading Dictionary object from deerwester.dict\n",
      "2018-08-08 21:56:19,260 : INFO : loaded deerwester.dict\n",
      "2018-08-08 21:56:19,261 : INFO : loaded corpus index from deerwester.mm.index\n",
      "2018-08-08 21:56:19,262 : INFO : initializing cython corpus reader from deerwester.mm\n",
      "2018-08-08 21:56:19,263 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n",
      "2018-08-08 21:56:19,264 : INFO : using serial LSI version on this node\n",
      "2018-08-08 21:56:19,265 : INFO : updating model with new documents\n",
      "2018-08-08 21:56:19,266 : INFO : preparing a new chunk of documents\n",
      "2018-08-08 21:56:19,266 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-08-08 21:56:19,267 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2018-08-08 21:56:19,268 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2018-08-08 21:56:19,269 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2018-08-08 21:56:19,270 : INFO : computing the final decomposition\n",
      "2018-08-08 21:56:19,271 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2018-08-08 21:56:19,272 : INFO : processed documents up to #9\n",
      "2018-08-08 21:56:19,273 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"time\" + 0.265*\"response\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2018-08-08 21:56:19,273 : INFO : topic #1(2.542): -0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"time\" + -0.107*\"response\" + 0.072*\"interface\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4618210045327162), (1, 0.07002766527899945)]\n"
     ]
    }
   ],
   "source": [
    "#similarity interface\n",
    "dictionary = corpora.Dictionary.load('deerwester.dict')\n",
    "corpus = corpora.MmCorpus('deerwester.mm')\n",
    "\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-08 21:57:42,466 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2018-08-08 21:57:42,468 : INFO : creating matrix with 9 documents and 2 features\n",
      "D:\\Anaconda\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "2018-08-08 21:57:42,471 : INFO : saving MatrixSimilarity object under deerwester.index, separately None\n",
      "2018-08-08 21:57:42,473 : INFO : saved deerwester.index\n",
      "2018-08-08 21:57:42,474 : INFO : loading MatrixSimilarity object from deerwester.index\n",
      "2018-08-08 21:57:42,476 : INFO : loaded deerwester.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.998093), (1, 0.93748635), (2, 0.9984453), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.09879464), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "#初始化查询结构\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "index.save('deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('deerwester.index')\n",
    "sims = index[vec_lsi]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-d0076a53a276>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-d0076a53a276>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    sims = sorted(enumerate(sims), key = lambda item item: -item[1])\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key = lambda item item: -item[1])\n",
    "print(sims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
